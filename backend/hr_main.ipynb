{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9506d074",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import glob\n",
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from google.api_core import retry\n",
    "from langcodes import Language\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "import fasttext\n",
    "import re\n",
    "from typing import Any, Dict, List, Tuple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d99da550",
   "metadata": {},
   "outputs": [],
   "source": [
    "def import_google_api():\n",
    "    load_dotenv()\n",
    "    GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "    client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "    # Simple model check\n",
    "    for m in client.models.list():\n",
    "        if \"embedContent\" in m.supported_actions:\n",
    "            print(m.name)\n",
    "\n",
    "    return client\n",
    "\n",
    "# %%\n",
    "def embedding_function(client):\n",
    "    class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "        document_mode = True\n",
    "\n",
    "        def __init__(self, client):\n",
    "            self.client = client\n",
    "            self._retry = retry.Retry(predicate=lambda e: isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "        def __call__(self, input: Documents) -> Embeddings:\n",
    "            embedding_task = \"retrieval_document\" if self.document_mode else \"retrieval_query\"\n",
    "            response = self._retry(self.client.models.embed_content)(\n",
    "                model=\"models/text-embedding-004\",\n",
    "                contents=input,\n",
    "                config=types.EmbedContentConfig(task_type=embedding_task),\n",
    "            )\n",
    "            return [e.values for e in response.embeddings]\n",
    "\n",
    "    return GeminiEmbeddingFunction(client)\n",
    "\n",
    "# %%\n",
    "class Document:\n",
    "    def __init__(self, page_content: str, metadata: dict = None):\n",
    "        self.page_content = page_content\n",
    "        self.metadata = metadata if metadata is not None else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "dcb7c25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_markdown_for_metadata(directory: str, google_drive_path: str = None) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Optimized parsing with lightweight metadata indexing.\n",
    "    Uses compact metadata prepending only when beneficial.\n",
    "    \"\"\"\n",
    "    markdown_files = glob.glob(os.path.join(directory, '**/*.md'), recursive=True)\n",
    "    if not markdown_files:\n",
    "        return []\n",
    "\n",
    "    headers_to_split_on = [(\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"###\", \"Header 3\")]\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=300)\n",
    "    \n",
    "    all_documents = []\n",
    "\n",
    "    for filepath in tqdm(markdown_files, desc=\"Processing documents\"):\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                markdown_text = f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            continue\n",
    "\n",
    "        filename_base = os.path.basename(filepath)\n",
    "        name_no_ext = os.path.splitext(filename_base)[0]\n",
    "        \n",
    "        # Clean document identifier\n",
    "        clean_id = name_no_ext.replace(\"fhs.hr_\", \"\") \n",
    "        doc_name_clean = clean_id.replace(\"_\", \" \")\n",
    "\n",
    "        md_header_splits = markdown_splitter.split_text(markdown_text)\n",
    "        final_splits = text_splitter.split_documents(md_header_splits)\n",
    "\n",
    "        for i, split in enumerate(final_splits):\n",
    "            # Generate header context\n",
    "            header_context = \" > \".join([v for k, v in split.metadata.items() if \"Header\" in k])\n",
    "            \n",
    "            # OPTIMIZED: Lightweight metadata prepending\n",
    "            # Only prepend for first chunk or when header exists\n",
    "            if i == 0 or header_context:\n",
    "                # Compact format: \"DocName | Section: content\"\n",
    "                metadata_prefix = f\"{doc_name_clean}\"\n",
    "                if header_context:\n",
    "                    metadata_prefix += f\" | {header_context}\"\n",
    "                searchable_content = f\"{metadata_prefix}: {split.page_content}\"\n",
    "            else:\n",
    "                # Subsequent chunks without headers: pure content\n",
    "                searchable_content = split.page_content\n",
    "            \n",
    "            # Create Document with optimized content\n",
    "            doc = Document(page_content=searchable_content)\n",
    "            \n",
    "            # Rich metadata for filtering (stored separately, not embedded)\n",
    "            doc.metadata = split.metadata.copy()\n",
    "            doc.metadata[\"source\"] = filename_base \n",
    "            doc.metadata[\"article_link\"] = clean_id \n",
    "            doc.metadata[\"doc_name\"] = doc_name_clean \n",
    "            doc.metadata[\"source_path\"] = google_drive_path or filepath\n",
    "            doc.metadata[\"chunk_index\"] = i\n",
    "            doc.metadata[\"total_chunks\"] = len(final_splits)\n",
    "            doc.metadata[\"header_path\"] = header_context\n",
    "            doc.metadata[\"is_first_chunk\"] = (i == 0)\n",
    "            \n",
    "            all_documents.append(doc)\n",
    "\n",
    "    return all_documents\n",
    "\n",
    "# %%\n",
    "def create_collection(chroma_client, gemini_embedding_function, documents_list):\n",
    "    \"\"\"\n",
    "    Create or update ChromaDB collection with optimized batch processing.\n",
    "    \"\"\"\n",
    "    DB_NAME = \"hrstud-bot-hr\"\n",
    "    embed_fn = gemini_embedding_function\n",
    "    embed_fn.document_mode = True\n",
    "\n",
    "    db = chroma_client.get_or_create_collection(\n",
    "        name=DB_NAME,\n",
    "        metadata={\"model\": \"models/text-embedding-004\", \"dimension\": 768},\n",
    "        embedding_function=embed_fn\n",
    "    )\n",
    "\n",
    "    documents = [doc.page_content for doc in documents_list]\n",
    "    metadatas = [doc.metadata for doc in documents_list]\n",
    "    ids = [f\"{DB_NAME}_doc_{i}\" for i in range(len(documents))]\n",
    "\n",
    "    if db.count() == 0:\n",
    "        print(f\"Adding {len(documents)} documents to ChromaDB collection: {DB_NAME}\")\n",
    "\n",
    "        BATCH_SIZE = 100\n",
    "        \n",
    "        for i in tqdm(range(0, len(documents), BATCH_SIZE), desc=\"Adding documents\", unit=\"batch\"):\n",
    "            batch_end = min(i + BATCH_SIZE, len(documents))\n",
    "            db.add(\n",
    "                documents=documents[i:batch_end],\n",
    "                metadatas=metadatas[i:batch_end],\n",
    "                ids=ids[i:batch_end]\n",
    "            )\n",
    "            time.sleep(0.2)\n",
    "\n",
    "        print(f\"\\nCollection '{DB_NAME}' now contains {db.count()} documents.\")\n",
    "    else:\n",
    "        print(f\"Collection '{DB_NAME}' already has {db.count()} documents.\")\n",
    "\n",
    "# %%\n",
    "def persistent_client(embed_fn):\n",
    "    \"\"\"\n",
    "    Initialize persistent ChromaDB client.\n",
    "    \"\"\"\n",
    "    persist_dir = \"./output_hr\"\n",
    "    chroma_client = chromadb.PersistentClient(path=persist_dir)\n",
    "\n",
    "    DB_NAME = \"hrstud-bot-hr\"\n",
    "    collection = chroma_client.get_collection(DB_NAME, embedding_function=embed_fn)\n",
    "\n",
    "    print(f\"Connected to collection: {collection.name}\")\n",
    "    print(f\"Documents: {collection.count()}\")\n",
    "    print(f\"Metadata: {collection.metadata}\")\n",
    "    return embed_fn, collection\n",
    "\n",
    "# %%\n",
    "def extract_document_filter(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract document/section filters from user query.\n",
    "    Returns ChromaDB where clause if specific document mentioned.\n",
    "    \"\"\"\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Common document name patterns\n",
    "    doc_patterns = {\n",
    "        \"upis\": [\"upis\", \"prijav\"],\n",
    "        \"studij\": [\"studij\", \"program\"],\n",
    "        \"raspored\": [\"raspored\", \"termin\"],\n",
    "        \"ispit\": [\"ispit\", \"kolokvij\"],\n",
    "    }\n",
    "    \n",
    "    for doc_key, patterns in doc_patterns.items():\n",
    "        if any(pattern in query_lower for pattern in patterns):\n",
    "            # Check if asking specifically about a document\n",
    "            if any(phrase in query_lower for phrase in [\"u dokumentu\", \"na stranici\", \"dokument o\"]):\n",
    "                return {\"doc_name\": {\"$contains\": doc_key}}\n",
    "    \n",
    "    return None  # No specific filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e725cc54",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_article_link_from_content(content: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract the article link from markdown content.\n",
    "    Only matches links with the exact text \"Article Link\".\n",
    "    \"\"\"\n",
    "    # Pattern: Exact match for [Article Link](URL)\n",
    "    link_pattern = r'\\[Article Link\\]\\((https?://[^\\)]+)\\)'\n",
    "    match = re.search(link_pattern, content[:1000])\n",
    "    \n",
    "    if match:\n",
    "        url = match.group(1)\n",
    "        return f\"[Article Link]({url})\"\n",
    "    \n",
    "    # Fallback: return None if no \"Article Link\" found\n",
    "    return None\n",
    "\n",
    "def get_article_hr(user_query, embed_fn, collection, client):\n",
    "    \"\"\"\n",
    "    Optimized retrieval with query expansion and metadata filtering.\n",
    "    Extracts article link from actual document content.\n",
    "    \"\"\"\n",
    "    # 1. QUERY PREPARATION\n",
    "    embed_fn.document_mode = False\n",
    "    query_lower = user_query.lower()\n",
    "    \n",
    "    # Initial values\n",
    "    expanded_query = user_query\n",
    "    n_results_to_fetch = 12\n",
    "    metadata_filter = extract_document_filter(user_query)\n",
    "\n",
    "    # 2. QUERY EXPANSION LOGIC\n",
    "    if any(word in query_lower for word in [\"predaje\", \"tko\", \"nastavnik\", \"profesor\", \"kolegij\"]):\n",
    "        expanded_query = f\"{user_query} profesor nositelj zvanje nastava kolegij studij\"\n",
    "    \n",
    "    elif any(word in query_lower for word in [\"doći\", \"lokacija\", \"gdje\", \"kampus\", \"borongaj\", \"autobus\", \"vlak\"]):\n",
    "        expanded_query = f\"{user_query} lokacija adresa kampus borongaj autobus 215 236 vlak stanica Trnava\"\n",
    "\n",
    "    elif any(word in query_lower for word in [\"studij\", \"nudite\", \"program\", \"upisi\", \"smjer\"]):\n",
    "        expanded_query = f\"{user_query} popis svih studija prijediplomski diplomski doktorski studij kroatologija povijest sociologija psihologija komunikologija filozofija\"\n",
    "        n_results_to_fetch = 20\n",
    "    \n",
    "    # 3. VECTOR SEARCH WITH OPTIONAL FILTERING\n",
    "    query_params = {\n",
    "        \"query_texts\": [expanded_query], \n",
    "        \"n_results\": n_results_to_fetch\n",
    "    }\n",
    "    \n",
    "    if metadata_filter:\n",
    "        query_params[\"where\"] = metadata_filter\n",
    "        print(f\"Applying metadata filter: {metadata_filter}\")\n",
    "    \n",
    "    result = collection.query(**query_params)\n",
    "    \n",
    "    all_passages = result[\"documents\"][0]\n",
    "    all_metadatas = result[\"metadatas\"][0]\n",
    "    all_distances = result[\"distances\"][0]\n",
    "\n",
    "    # 4. EXTRACT ARTICLE LINK FROM TOP RESULT CONTENT\n",
    "    article_link_markdown = None\n",
    "    if all_passages:\n",
    "        # Try to extract from the top result's content\n",
    "        article_link_markdown = extract_article_link_from_content(all_passages[0])\n",
    "        \n",
    "        # Fallback to metadata if extraction fails\n",
    "        if not article_link_markdown:\n",
    "            main_url = all_metadatas[0].get(\"article_link\", \"\")\n",
    "            if main_url:\n",
    "                article_link_markdown = f\"[{main_url}](https://www.fhs.hr/{main_url})\"\n",
    "            else:\n",
    "                article_link_markdown = \"[Fakultet Hrvatskih studija](https://www.fhs.hr)\"\n",
    "\n",
    "    # 5. DEDUPLICATION & CONTEXT PREPARATION\n",
    "    context_list = []\n",
    "    seen_passages = set()\n",
    "    \n",
    "    # Dynamic threshold based on query type\n",
    "    distance_threshold = 0.85 if \"studij\" in query_lower else 0.90\n",
    "    \n",
    "    for p, m, d in zip(all_passages, all_metadatas, all_distances):\n",
    "        if d < distance_threshold:\n",
    "            # Use first 200 chars as fingerprint\n",
    "            fingerprint = p.strip()[:200]\n",
    "            if fingerprint in seen_passages:\n",
    "                continue\n",
    "            seen_passages.add(fingerprint)\n",
    "            \n",
    "            chunk_url = m.get(\"article_link\", \"\")\n",
    "            header = m.get(\"header_path\", \"\")\n",
    "            \n",
    "            # Include header context if available\n",
    "            context_entry = f\"Izvor URL: {chunk_url}\"\n",
    "            if header:\n",
    "                context_entry += f\"\\nSekcija: {header}\"\n",
    "            context_entry += f\"\\n{p.strip()}\"\n",
    "            \n",
    "            context_list.append(context_entry)\n",
    "\n",
    "    if not context_list:\n",
    "        return \"Nažalost, ne mogu pronaći informacije o vašem upitu u bazi znanja. Molimo kontaktirajte studentsku službu za dodatne informacije.\"\n",
    "\n",
    "    context = \"\\n\\n\".join(context_list)\n",
    "    query_oneline = user_query.replace(\"\\n\", \" \")\n",
    "\n",
    "    # 6. OPTIMIZED PROMPT\n",
    "    prompt = f\"\"\"Ti si ljubazan, precizan i informativan chatbot **Fakulteta Hrvatskih studija**. Tvoja je zadaća odgovarati na pitanja o fakultetu.\n",
    "\n",
    "**KRITIČNA PRAVILA:**\n",
    "1. Koristi ISKLJUČIVO dostavljenu dokumentaciju (KONTEKST).\n",
    "2. Odgovaraj na **Hrvatskom jeziku**.\n",
    "3. **GRUPIRANJE:** Ako ista osoba predaje više kolegija, navedi ime SAMO JEDNOM. Grupiraj studije po razinama.\n",
    "4. **POVEZNICE:** Kolegije, emailove i studije prikaži kao Markdown poveznice [Naziv](URL).\n",
    "5. **BEZ UVODA:** Odmah započni s relevantnim odgovorom bez fraza poput \"Naravno...\".\n",
    "\n",
    "**FORMATIRANJE:**\n",
    "* Prva linija: **Izvor:** Link koji ti se iz dokumentacije čini najrelevantnijim.\n",
    "* Prazan red nakon izvora.\n",
    "* **Podebljani tekst** za ključne pojmove.\n",
    "* Liste (bullet points) za nabrajanje.\n",
    "* Ako je navedeni link u ovom formatu npr. u ovom slučaju za Email: E-mail: [idzinic@fhs.hr](javascript:startMail('qvvmva@pus.feu');)\n",
    "    - prikaži kao običnu poveznicu bez javascript dijela, npr. E-mail: idzinic@fhs.hr\n",
    "    - makni javascript dio iz poveznice za svaku poveznicu\n",
    "**DOSTUPNA DOKUMENTACIJA:**\n",
    "{context}\n",
    "\n",
    "**KORISNIČKO PITANJE:** {query_oneline}\n",
    "\n",
    "**ODGOVOR:**\"\"\"\n",
    "    \n",
    "    # 7. GENERATE RESPONSE\n",
    "    answer = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash-exp\",\n",
    "        contents=prompt,\n",
    "        config={\n",
    "            \"max_output_tokens\": 2048,\n",
    "            \"temperature\": 0.1,\n",
    "            \"top_p\": 0.9\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return answer.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "dab66e54",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 1095/1095 [00:00<00:00, 1378.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "Collection 'hrstud-bot-hr' already has 6776 documents.\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "Connected to collection: hrstud-bot-hr\n",
      "Documents: 6776\n",
      "Metadata: {'model': 'models/text-embedding-004', 'dimension': 768}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Izvor:** [https://www.fhs.hr/djelatnik/ivo.dzinic](https://www.fhs.hr/djelatnik/ivo.dzinic)\n",
       "\n",
       "**Ivo Džinić** je redoviti profesor na Odsjeku za filozofiju i kulturologiju Fakulteta hrvatskih studija Sveučilišta u Zagrebu od 2018. godine.\n",
       "\n",
       "**Kontakt:**\n",
       "*   Kabinet: Building 78, room 23\n",
       "*   Konzultacije: petkom od 11 do 12 sati\n",
       "*   Telefon: 01 245-7622, 7622\n",
       "*   E-mail: [idzinic@fhs.hr](mailto:idzinic@fhs.hr)\n",
       "\n",
       "**Nastava:**\n",
       "Ivo Džinić je nositelj i/ili seminarist na sljedećim kolegijima:\n",
       "\n",
       "*   **Prijediplomski studij:**\n",
       "    *   [Antička filozofija (214822)](https://www.fhs.hr/predmet/antfil_a) - Nositelj\n",
       "    *   [Filozofija kulture (214828)](https://www.fhs.hr/predmet/filkul_a) - Nositelj\n",
       "    *   [Filozofska kulturna antropologija (214823)](https://www.fhs.hr/predmet/fka_a) - Nositelj\n",
       "    *   [Filozofsko-teološki pristup stanovništvu (214008)](https://www.fhs.hr/predmet/fps) - Nositelj, Seminar\n",
       "    *   [Uvod u kulturologiju (214820)](https://www.fhs.hr/predmet/uuk_b) - Nositelj\n",
       "    *   [Završni rad (38774)](https://www.fhs.hr/predmet/zavrad) - Seminar\n",
       "*   **Diplomski studij:**\n",
       "    *   [Filozofija mita i religije (187904)](https://www.fhs.hr/predmet/fmr) - Nositelj, Seminar\n",
       "    *   [Diplomski rad (214814)](https://www.fhs.hr/predmet/diprad_f) - Seminar\n",
       "*   **Doktorski studij:**\n",
       "    *   [Hermeneutika (258229)](https://www.fhs.hr/predmet/her) - Nositelj\n",
       "\n",
       "Područja znanstvenog interesa su mu filozofija kulture, filozofska i kulturna antropologija, filozofije mita i religije, te izabrane teme iz praktične teologije. Član je Hrvatskog filozofskog društva i Mreže pastoralnih teologa Srednje i Istočne Europe."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'test_queries = [\\n    \"Koje predmete predaje Mato Škerbić?\",\\n    \"Kako doći do kampusa?\",\\n    \"Koji studiji su dostupni na fakultetu?\"\\n]\\n\\nfor query in test_queries:\\n    print(f\"\\n{\\'#\\'*60}\")\\n    print(f\"QUERY: {query}\")\\n    print(f\"{\\'#\\'*60}\")\\n    response = get_article_hr(\\n        user_query=query,\\n        embed_fn=embed_fn,\\n        collection=collection,\\n        client=client,\\n    )\\n    display(Markdown(response))\\n    print(\"\\n\")'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "# USAGE EXAMPLE\n",
    "\n",
    "markdown_folder = \"./markdown_hr\"\n",
    "\n",
    "# STEP 1: Parse and chunk documents (run once or when documents change)\n",
    "md_documents = parse_markdown_for_metadata(markdown_folder)\n",
    "\n",
    "# STEP 2: Create collection and add documents (run once)\n",
    "client = import_google_api()\n",
    "gemini_embedding_function = embedding_function(client)\n",
    "chroma_persistent_client = chromadb.PersistentClient(path=\"./output_hr\")\n",
    "create_collection(chroma_persistent_client, gemini_embedding_function, md_documents)\n",
    "\n",
    "# %%\n",
    "# STEP 3: Query the system\n",
    "\n",
    "client = import_google_api()\n",
    "gemini_embedding_function = embedding_function(client)\n",
    "embed_fn, collection = persistent_client(gemini_embedding_function)\n",
    "\n",
    "user_query = \"tko je ivo džinić?\"\n",
    "response = get_article_hr(\n",
    "    user_query=user_query,\n",
    "    embed_fn=embed_fn,\n",
    "    collection=collection,\n",
    "    client=client\n",
    ")\n",
    "display(Markdown(response))\n",
    "\n",
    "# %%\n",
    "# ADVANCED: Test multiple queries\n",
    "\n",
    "'''test_queries = [\n",
    "    \"Koje predmete predaje Mato Škerbić?\",\n",
    "    \"Kako doći do kampusa?\",\n",
    "    \"Koji studiji su dostupni na fakultetu?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'#'*60}\")\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(f\"{'#'*60}\")\n",
    "    response = get_article_hr(\n",
    "        user_query=query,\n",
    "        embed_fn=embed_fn,\n",
    "        collection=collection,\n",
    "        client=client,\n",
    "    )\n",
    "    display(Markdown(response))\n",
    "    print(\"\\n\")'''"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
