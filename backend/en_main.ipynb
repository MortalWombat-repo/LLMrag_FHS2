{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "455b301e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "import sys\n",
    "import time\n",
    "from google import genai\n",
    "from google.genai import types\n",
    "from IPython.display import Markdown\n",
    "from IPython.display import display\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "import glob\n",
    "import chromadb\n",
    "from chromadb import Documents, EmbeddingFunction, Embeddings\n",
    "from google.api_core import retry\n",
    "from langcodes import Language\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "from langchain_text_splitters import MarkdownHeaderTextSplitter, RecursiveCharacterTextSplitter\n",
    "from langchain_core.documents import Document\n",
    "import re\n",
    "from collections import defaultdict\n",
    "from typing import List, Tuple\n",
    "import fasttext\n",
    "import re\n",
    "from typing import Any, Dict, List, Tuple\n",
    "\n",
    "# %%\n",
    "def import_google_api():\n",
    "    load_dotenv()\n",
    "    GOOGLE_API_KEY = os.getenv(\"GOOGLE_API_KEY\")\n",
    "\n",
    "    client = genai.Client(api_key=GOOGLE_API_KEY)\n",
    "\n",
    "    # Simple model check\n",
    "    for m in client.models.list():\n",
    "        if \"embedContent\" in m.supported_actions:\n",
    "            print(m.name)\n",
    "\n",
    "    return client\n",
    "\n",
    "# %%\n",
    "def embedding_function(client):\n",
    "    class GeminiEmbeddingFunction(EmbeddingFunction):\n",
    "        document_mode = True\n",
    "\n",
    "        def __init__(self, client):\n",
    "            self.client = client\n",
    "            self._retry = retry.Retry(predicate=lambda e: isinstance(e, genai.errors.APIError) and e.code in {429, 503})\n",
    "\n",
    "        def __call__(self, input: Documents) -> Embeddings:\n",
    "            embedding_task = \"retrieval_document\" if self.document_mode else \"retrieval_query\"\n",
    "            response = self._retry(self.client.models.embed_content)(\n",
    "                model=\"models/text-embedding-004\",\n",
    "                contents=input,\n",
    "                config=types.EmbedContentConfig(task_type=embedding_task),\n",
    "            )\n",
    "            return [e.values for e in response.embeddings]\n",
    "\n",
    "    return GeminiEmbeddingFunction(client)\n",
    "\n",
    "# %%\n",
    "class Document:\n",
    "    def __init__(self, page_content: str, metadata: dict = None):\n",
    "        self.page_content = page_content\n",
    "        self.metadata = metadata if metadata is not None else {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9cff1106",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "def parse_markdown_for_metadata(directory: str, google_drive_path: str = None) -> List[Document]:\n",
    "    \"\"\"\n",
    "    Optimized parsing with lightweight metadata indexing.\n",
    "    Uses compact metadata prepending only when beneficial.\n",
    "    \"\"\"\n",
    "    markdown_files = glob.glob(os.path.join(directory, '**/*.md'), recursive=True)\n",
    "    if not markdown_files:\n",
    "        return []\n",
    "\n",
    "    headers_to_split_on = [(\"#\", \"Header 1\"), (\"##\", \"Header 2\"), (\"###\", \"Header 3\")]\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "    text_splitter = RecursiveCharacterTextSplitter(chunk_size=2000, chunk_overlap=300)\n",
    "    \n",
    "    all_documents = []\n",
    "\n",
    "    for filepath in tqdm(markdown_files, desc=\"Processing documents\"):\n",
    "        try:\n",
    "            with open(filepath, 'r', encoding='utf-8') as f:\n",
    "                markdown_text = f.read()\n",
    "        except Exception as e:\n",
    "            print(f\"Error: {e}\")\n",
    "            continue\n",
    "\n",
    "        filename_base = os.path.basename(filepath)\n",
    "        name_no_ext = os.path.splitext(filename_base)[0]\n",
    "        \n",
    "        # Clean document identifier\n",
    "        clean_id = name_no_ext.replace(\"fhs.hr_\", \"\") \n",
    "        doc_name_clean = clean_id.replace(\"_\", \" \")\n",
    "\n",
    "        md_header_splits = markdown_splitter.split_text(markdown_text)\n",
    "        final_splits = text_splitter.split_documents(md_header_splits)\n",
    "\n",
    "        for i, split in enumerate(final_splits):\n",
    "            # Generate header context\n",
    "            header_context = \" > \".join([v for k, v in split.metadata.items() if \"Header\" in k])\n",
    "            \n",
    "            # OPTIMIZED: Lightweight metadata prepending\n",
    "            # Only prepend for first chunk or when header exists\n",
    "            if i == 0 or header_context:\n",
    "                # Compact format: \"DocName | Section: content\"\n",
    "                metadata_prefix = f\"{doc_name_clean}\"\n",
    "                if header_context:\n",
    "                    metadata_prefix += f\" | {header_context}\"\n",
    "                searchable_content = f\"{metadata_prefix}: {split.page_content}\"\n",
    "            else:\n",
    "                # Subsequent chunks without headers: pure content\n",
    "                searchable_content = split.page_content\n",
    "            \n",
    "            # Create Document with optimized content\n",
    "            doc = Document(page_content=searchable_content)\n",
    "            \n",
    "            # Rich metadata for filtering (stored separately, not embedded)\n",
    "            doc.metadata = split.metadata.copy()\n",
    "            doc.metadata[\"source\"] = filename_base \n",
    "            doc.metadata[\"article_link\"] = clean_id \n",
    "            doc.metadata[\"doc_name\"] = doc_name_clean \n",
    "            doc.metadata[\"source_path\"] = google_drive_path or filepath\n",
    "            doc.metadata[\"chunk_index\"] = i\n",
    "            doc.metadata[\"total_chunks\"] = len(final_splits)\n",
    "            doc.metadata[\"header_path\"] = header_context\n",
    "            doc.metadata[\"is_first_chunk\"] = (i == 0)\n",
    "            \n",
    "            all_documents.append(doc)\n",
    "\n",
    "    return all_documents\n",
    "\n",
    "# %%\n",
    "def create_collection(chroma_client, gemini_embedding_function, documents_list):\n",
    "    \"\"\"\n",
    "    Create or update ChromaDB collection with optimized batch processing.\n",
    "    \"\"\"\n",
    "    DB_NAME = \"hrstud-bot-en\"\n",
    "    embed_fn = gemini_embedding_function\n",
    "    embed_fn.document_mode = True\n",
    "\n",
    "    db = chroma_client.get_or_create_collection(\n",
    "        name=DB_NAME,\n",
    "        metadata={\"model\": \"models/text-embedding-004\", \"dimension\": 768},\n",
    "        embedding_function=embed_fn\n",
    "    )\n",
    "\n",
    "    documents = [doc.page_content for doc in documents_list]\n",
    "    metadatas = [doc.metadata for doc in documents_list]\n",
    "    ids = [f\"{DB_NAME}_doc_{i}\" for i in range(len(documents))]\n",
    "\n",
    "    if db.count() == 0:\n",
    "        print(f\"Adding {len(documents)} documents to ChromaDB collection: {DB_NAME}\")\n",
    "\n",
    "        BATCH_SIZE = 100\n",
    "        \n",
    "        for i in tqdm(range(0, len(documents), BATCH_SIZE), desc=\"Adding documents\", unit=\"batch\"):\n",
    "            batch_end = min(i + BATCH_SIZE, len(documents))\n",
    "            db.add(\n",
    "                documents=documents[i:batch_end],\n",
    "                metadatas=metadatas[i:batch_end],\n",
    "                ids=ids[i:batch_end]\n",
    "            )\n",
    "            time.sleep(0.2)\n",
    "\n",
    "        print(f\"\\nCollection '{DB_NAME}' now contains {db.count()} documents.\")\n",
    "    else:\n",
    "        print(f\"Collection '{DB_NAME}' already has {db.count()} documents.\")\n",
    "\n",
    "# %%\n",
    "def persistent_client(embed_fn):\n",
    "    \"\"\"\n",
    "    Initialize persistent ChromaDB client.\n",
    "    \"\"\"\n",
    "    persist_dir = \"./output_en\"\n",
    "    chroma_client = chromadb.PersistentClient(path=persist_dir)\n",
    "\n",
    "    DB_NAME = \"hrstud-bot-en\"\n",
    "    collection = chroma_client.get_collection(DB_NAME, embedding_function=embed_fn)\n",
    "\n",
    "    print(f\"Connected to collection: {collection.name}\")\n",
    "    print(f\"Documents: {collection.count()}\")\n",
    "    print(f\"Metadata: {collection.metadata}\")\n",
    "    return embed_fn, collection\n",
    "\n",
    "# %%\n",
    "def extract_document_filter(query: str) -> dict:\n",
    "    \"\"\"\n",
    "    Extract document/section filters from user query.\n",
    "    Returns ChromaDB where clause if specific document mentioned.\n",
    "    \"\"\"\n",
    "    query_lower = query.lower()\n",
    "    \n",
    "    # Common document name patterns\n",
    "    doc_patterns = {\n",
    "        \"admission\": [\"admission\", \"enroll\", \"apply\"],\n",
    "        \"program\": [\"program\", \"study\", \"course\"],\n",
    "        \"schedule\": [\"schedule\", \"timetable\"],\n",
    "        \"exam\": [\"exam\", \"test\", \"assessment\"],\n",
    "    }\n",
    "    \n",
    "    for doc_key, patterns in doc_patterns.items():\n",
    "        if any(pattern in query_lower for pattern in patterns):\n",
    "            # Check if asking specifically about a document\n",
    "            if any(phrase in query_lower for phrase in [\"in the document\", \"on the page\", \"document about\"]):\n",
    "                return {\"doc_name\": {\"$contains\": doc_key}}\n",
    "    \n",
    "    return None  # No specific filter\n",
    "\n",
    "# %%\n",
    "def extract_article_link_from_content(content: str) -> str:\n",
    "    \"\"\"\n",
    "    Extract the article link from markdown content.\n",
    "    Only matches links with the exact text \"Article Link\".\n",
    "    \"\"\"\n",
    "    # Pattern: Exact match for [Article Link](URL)\n",
    "    link_pattern = r'\\[Article Link\\]\\((https?://[^\\)]+)\\)'\n",
    "    match = re.search(link_pattern, content[:1000])\n",
    "    \n",
    "    if match:\n",
    "        url = match.group(1)\n",
    "        return f\"[Article Link]({url})\"\n",
    "    \n",
    "    # Fallback: return None if no \"Article Link\" found\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b53f467e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_article_en(user_query, embed_fn, collection, client):\n",
    "    \"\"\"\n",
    "    Optimized retrieval with query expansion and metadata filtering.\n",
    "    Extracts article link from actual document content.\n",
    "    \"\"\"\n",
    "    # 1. QUERY PREPARATION\n",
    "    embed_fn.document_mode = False\n",
    "    query_lower = user_query.lower()\n",
    "    \n",
    "    # Initial values\n",
    "    expanded_query = user_query\n",
    "    n_results_to_fetch = 12\n",
    "    metadata_filter = extract_document_filter(user_query)\n",
    "\n",
    "    # 2. QUERY EXPANSION LOGIC\n",
    "    if any(word in query_lower for word in [\"teaches\", \"who\", \"professor\", \"instructor\", \"course\", \"class\"]):\n",
    "        expanded_query = f\"{user_query} professor instructor title teaching course class program study\"\n",
    "    \n",
    "    elif any(word in query_lower for word in [\"get to\", \"location\", \"where\", \"campus\", \"borongaj\", \"bus\", \"train\"]):\n",
    "        expanded_query = f\"{user_query} location address campus borongaj bus 215 236 train station Trnava\"\n",
    "\n",
    "    elif any(word in query_lower for word in [\"program\", \"offer\", \"study\", \"admission\", \"major\"]):\n",
    "        expanded_query = f\"{user_query} list of programs undergraduate graduate doctoral study croatology history sociology psychology communication philosophy\"\n",
    "        n_results_to_fetch = 20\n",
    "    \n",
    "    # 3. VECTOR SEARCH WITH OPTIONAL FILTERING\n",
    "    query_params = {\n",
    "        \"query_texts\": [expanded_query], \n",
    "        \"n_results\": n_results_to_fetch\n",
    "    }\n",
    "    \n",
    "    if metadata_filter:\n",
    "        query_params[\"where\"] = metadata_filter\n",
    "        print(f\"Applying metadata filter: {metadata_filter}\")\n",
    "    \n",
    "    result = collection.query(**query_params)\n",
    "    \n",
    "    all_passages = result[\"documents\"][0]\n",
    "    all_metadatas = result[\"metadatas\"][0]\n",
    "    all_distances = result[\"distances\"][0]\n",
    "\n",
    "    # 4. EXTRACT ARTICLE LINK FROM TOP RESULT CONTENT\n",
    "    article_link_markdown = None\n",
    "    if all_passages:\n",
    "        # Try to extract from the top result's content\n",
    "        article_link_markdown = extract_article_link_from_content(all_passages[0])\n",
    "        \n",
    "        # Fallback to metadata if extraction fails\n",
    "        if not article_link_markdown:\n",
    "            main_url = all_metadatas[0].get(\"article_link\", \"\")\n",
    "            if main_url:\n",
    "                article_link_markdown = f\"[{main_url}](https://www.fhs.hr/{main_url})\"\n",
    "            else:\n",
    "                article_link_markdown = \"[Faculty of Croatian Studies](https://www.fhs.hr)\"\n",
    "\n",
    "    # 5. DEDUPLICATION & CONTEXT PREPARATION\n",
    "    context_list = []\n",
    "    seen_passages = set()\n",
    "    \n",
    "    # Dynamic threshold based on query type\n",
    "    distance_threshold = 0.85 if \"program\" in query_lower or \"study\" in query_lower else 0.90\n",
    "    \n",
    "    for p, m, d in zip(all_passages, all_metadatas, all_distances):\n",
    "        if d < distance_threshold:\n",
    "            # Use first 200 chars as fingerprint\n",
    "            fingerprint = p.strip()[:200]\n",
    "            if fingerprint in seen_passages:\n",
    "                continue\n",
    "            seen_passages.add(fingerprint)\n",
    "            \n",
    "            chunk_url = m.get(\"article_link\", \"\")\n",
    "            header = m.get(\"header_path\", \"\")\n",
    "            \n",
    "            # Include header context if available\n",
    "            context_entry = f\"Source URL: {chunk_url}\"\n",
    "            if header:\n",
    "                context_entry += f\"\\nSection: {header}\"\n",
    "            context_entry += f\"\\n{p.strip()}\"\n",
    "            \n",
    "            context_list.append(context_entry)\n",
    "\n",
    "    if not context_list:\n",
    "        return \"Unfortunately, I cannot find information about your query in the knowledge base. Please contact the student office for additional information.\"\n",
    "\n",
    "    context = \"\\n\\n\".join(context_list)\n",
    "    query_oneline = user_query.replace(\"\\n\", \" \")\n",
    "\n",
    "    # 6. OPTIMIZED PROMPT\n",
    "    prompt = f\"\"\"You are a kind, precise, and informative chatbot for the **Faculty of Croatian Studies**. Your task is to answer questions about the faculty.\n",
    "\n",
    "**CRITICAL RULES:**\n",
    "1. Use ONLY the provided documentation (CONTEXT).\n",
    "2. Respond in **English**.\n",
    "3. **GROUPING:** If the same person teaches multiple courses, mention their name ONLY ONCE. Group programs by level.\n",
    "4. **LINKS:** Display courses, emails, and programs as Markdown links [Name](URL).\n",
    "5. **NO INTRODUCTION:** Start directly with the relevant answer without phrases like \"Of course...\".\n",
    "\n",
    "**FORMATTING:**\n",
    "* First line: **Source:** The link that seems most relevant from the documentation.\n",
    "* Blank line after source.\n",
    "* **Bold text** for key terms.\n",
    "* Lists (bullet points) for enumeration.\n",
    "* If the provided link is in this format, e.g., for Email: E-mail: [idzinic@fhs.hr](javascript:startMail('qvvmva@pus.feu');)\n",
    "    - display as a plain link without the javascript part, e.g., E-mail: idzinic@fhs.hr\n",
    "    - remove the javascript part from the link for every link\n",
    "**AVAILABLE DOCUMENTATION:**\n",
    "{context}\n",
    "\n",
    "**USER QUESTION:** {query_oneline}\n",
    "\n",
    "**ANSWER:**\"\"\"\n",
    "    \n",
    "    # 7. GENERATE RESPONSE\n",
    "    answer = client.models.generate_content(\n",
    "        model=\"gemini-2.0-flash-exp\",\n",
    "        contents=prompt,\n",
    "        config={\n",
    "            \"max_output_tokens\": 2048,\n",
    "            \"temperature\": 0.1,\n",
    "            \"top_p\": 0.9\n",
    "        }\n",
    "    )\n",
    "    \n",
    "    return answer.text.strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "481c3749",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing documents: 100%|██████████| 820/820 [00:01<00:00, 489.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "Adding 5857 documents to ChromaDB collection: hrstud-bot-en\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Adding documents: 100%|██████████| 59/59 [01:43<00:00,  1.76s/batch]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Collection 'hrstud-bot-en' now contains 5857 documents.\n",
      "models/embedding-001\n",
      "models/text-embedding-004\n",
      "models/gemini-embedding-exp-03-07\n",
      "models/gemini-embedding-exp\n",
      "models/gemini-embedding-001\n",
      "Connected to collection: hrstud-bot-en\n",
      "Documents: 5857\n",
      "Metadata: {'dimension': 768, 'model': 'models/text-embedding-004'}\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Source:** [staff_ivo.dzinic](https://www.fhs.hr/staff/ivo.dzinic)\n",
       "\n",
       "**Ivo Džinić** is a Full Professor at the Faculty of Croatian Studies, in the Department of Philosophy and Cultural Studies.\n",
       "\n",
       "His contact information:\n",
       "*   Cabinet: Building 78, room 23\n",
       "*   Consultations: On Fridays, from 11 am to 12 am\n",
       "*   Public phone number: 01 245-7622\n",
       "*   Internal phone number: 7622\n",
       "*   E-mail: [idzinic@fhs.hr](mailto:idzinic@fhs.hr)\n",
       "\n",
       "He teaches the following courses:\n",
       "\n",
       "**Undergraduate:**\n",
       "*   [Ancient Philosophy (214822)](https://www.fhs.hr/en/course/ancphi_a)\n",
       "*   [A Philosophical and Theological Approach to Population (214008)](https://www.fhs.hr/en/course/apatatp)\n",
       "*   [Introduction to Cultural Studies (214820)](https://www.fhs.hr/en/course/itcs_b)\n",
       "*   [Philosophical and Cultural Anthropology (214823)](https://www.fhs.hr/en/course/paca_a)\n",
       "*   [Philosophy of Culture (214828)](https://www.fhs.hr/en/course/poc_f)\n",
       "\n",
       "**Graduate:**\n",
       "*   [Philosophy of Myth and Religion (187904)](https://www.fhs.hr/en/course/pomar)\n",
       "\n",
       "**Doctoral:**\n",
       "*   [Hermeneutics (258229)](https://www.fhs.hr/en/course/her)\n",
       "\n",
       "He was born in Vinkovci in 1975. He speaks Croatian, German, English and Italian and reads Latin and Ancient Greek. He is married and the father of one child."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "############################################################\n",
      "QUERY: What classes does Mato Škerbić teach?\n",
      "############################################################\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Source:** [staff_matija_mato.skerbic](https://www.fhs.hr/staff/matija_mato.skerbic)\n",
       "\n",
       "**Matija Mato Škerbić** teaches the following courses:\n",
       "\n",
       "**Undergraduate:**\n",
       "*   [Ethics (214834)](https://www.fhs.hr/en/course/eth_a)\n",
       "*   [Integrative Bioethics (214015)](https://www.fhs.hr/en/course/intbio)\n",
       "*   [New ethical culture (187891)](https://www.fhs.hr/en/course/nec)\n",
       "\n",
       "**Graduate:**\n",
       "*   [Methods of Teaching Philosophy, Logic and Ethics (214635)](https://www.fhs.hr/en/course/motplae)\n",
       "*   [Philosophical methodology (201535)](https://www.fhs.hr/en/course/phimet)\n",
       "*   [Philosophy of Education (61957)](https://www.fhs.hr/en/course/poe)\n",
       "*   [Philosophy of Game and Sports (187914)](https://www.fhs.hr/en/course/pogas)\n",
       "*   [Master thesis (214814)](https://www.fhs.hr/en/course/masthe_b)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "############################################################\n",
      "QUERY: How do I get to campus?\n",
      "############################################################\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "There is no information about how to get to campus in the provided documentation."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\n",
      "############################################################\n",
      "QUERY: What study programs are available at the faculty?\n",
      "############################################################\n"
     ]
    },
    {
     "data": {
      "text/markdown": [
       "**Source:** [https://www.fhs.unizg.hr/en/study](https://www.fhs.unizg.hr/en/study)\n",
       "\n",
       "The Faculty of Croatian Studies offers the following study programs:\n",
       "\n",
       "*   [Undergraduate Study](https://www.fhs.unizg.hr/en/undergraduate_study)\n",
       "*   [Graduate Study](https://www.fhs.unizg.hr/en/graduate_study)\n",
       "*   [Postgraduate Study](https://www.fhs.unizg.hr/en/postgraduate_study)\n",
       "*   [Lifelong learning programs](https://www.fhs.unizg.hr/en/study/lifelong_learning_programs)\n",
       "\n",
       "Here is a breakdown of the single and double major programs at the undergraduate and graduate levels:\n",
       "\n",
       "**Undergraduate Programs:**\n",
       "\n",
       "*   Single Major:\n",
       "    *   [Communication Studies](https://www.fhs.unizg.hr/en/undergraduate_study/communication_sciences)\n",
       "    *   [Croatology](https://www.fhs.unizg.hr/en/undergraduate_study/croatology)\n",
       "    *   [History](https://www.fhs.unizg.hr/en/undergraduate_study/history)\n",
       "    *   [Psychology](https://www.fhs.unizg.hr/en/undergraduate_study/psychology)\n",
       "    *   [Sociology](https://www.fhs.unizg.hr/en/undergraduate_study/sociology)\n",
       "*   Double Major:\n",
       "    *   [Philosophy and Culture](https://www.fhs.unizg.hr/en/undergraduate_study/double_major/philosophy)\n",
       "    *   [Communication Studies](https://www.fhs.unizg.hr/en/undergraduate_study/double_major/com)\n",
       "    *   [Croatology](https://www.fhs.unizg.hr/en/undergraduate_study/double_major/croatian_studies)\n",
       "    *   [Latin Language](https://www.fhs.unizg.hr/en/undergraduate_study/double_major/latin_language)\n",
       "    *   [History](https://www.fhs.unizg.hr/en/undergraduate_study/double_major/history)\n",
       "    *   [Sociology](https://www.fhs.unizg.hr/en/undergraduate_study/double_major/sociology)\n",
       "\n",
       "**Graduate Programs:**\n",
       "\n",
       "*   Single Major:\n",
       "    *   [Communication Studies](https://www.fhs.unizg.hr/en/graduade_study/communicology)\n",
       "    *   [Croatology](https://www.fhs.unizg.hr/en/graduade_study/croatology/teaching_stream)\n",
       "    *   [History](https://www.fhs.unizg.hr/en/graduade_study/history/science_stream)\n",
       "    *   [Psychology](https://www.fhs.unizg.hr/en/graduade_study/psychology)\n",
       "    *   [Sociology](https://www.fhs.unizg.hr/en/graduade_study/sociology/science_stream)\n",
       "*   Double Major:\n",
       "    *   [Croatian latinity](https://www.fhs.unizg.hr/en/graduade_study/croatian_latinity)\n",
       "    *   [Croatology](https://www.fhs.unizg.hr/en/graduade_study/croatology/double_major)\n",
       "    *   [History](https://www.fhs.unizg.hr/en/graduade_study/history/double_major)\n",
       "    *   [Philosophy](https://www.fhs.unizg.hr/en/graduade_study/philosophy/double_major)\n",
       "    *   [Sociology](https://www.fhs.unizg.hr/en/graduade_study/sociology/teaching_stream)\n",
       "\n",
       "**Postgraduate Programs:**\n",
       "\n",
       "*   [Croatology](https://www.fhs.hr/croatology)\n",
       "*   [History](https://www.fhs.hr/history)\n",
       "*   [Philosophy](https://www.fhs.hr/philosophy)"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "# USAGE EXAMPLE\n",
    "\n",
    "markdown_folder = \"./markdown_en\"\n",
    "\n",
    "# STEP 1: Parse and chunk documents (run once or when documents change)\n",
    "md_documents = parse_markdown_for_metadata(markdown_folder)\n",
    "\n",
    "# STEP 2: Create collection and add documents (run once)\n",
    "client = import_google_api()\n",
    "gemini_embedding_function = embedding_function(client)\n",
    "chroma_persistent_client = chromadb.PersistentClient(path=\"./output_en\")\n",
    "create_collection(chroma_persistent_client, gemini_embedding_function, md_documents)\n",
    "\n",
    "# %%\n",
    "# STEP 3: Query the system\n",
    "\n",
    "client = import_google_api()\n",
    "gemini_embedding_function = embedding_function(client)\n",
    "embed_fn, collection = persistent_client(gemini_embedding_function)\n",
    "\n",
    "user_query = \"Who is Ivo Džinić?\"\n",
    "response = get_article_en(\n",
    "    user_query=user_query,\n",
    "    embed_fn=embed_fn,\n",
    "    collection=collection,\n",
    "    client=client\n",
    ")\n",
    "display(Markdown(response))\n",
    "\n",
    "# %%\n",
    "# ADVANCED: Test multiple queries\n",
    "\n",
    "test_queries = [\n",
    "    \"What classes does Mato Škerbić teach?\",\n",
    "    \"How do I get to campus?\",\n",
    "    \"What study programs are available at the faculty?\"\n",
    "]\n",
    "\n",
    "for query in test_queries:\n",
    "    print(f\"\\n{'#'*60}\")\n",
    "    print(f\"QUERY: {query}\")\n",
    "    print(f\"{'#'*60}\")\n",
    "    response = get_article_en(\n",
    "        user_query=query,\n",
    "        embed_fn=embed_fn,\n",
    "        collection=collection,\n",
    "        client=client,\n",
    "    )\n",
    "    display(Markdown(response))\n",
    "    print(\"\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
